
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="keywords" content="eccv, workshop, computer vision, natural language processing, computer graphics, visual learning, machine learning">

  <link rel="shortcut icon" href="static/img/site/favicon.png">

  <title>GenAIMAGIC@CVPR25</title>
  <meta name="description" content="2nd GenAI Media Generation Challenge, CVPR 2025 Workshop">

  <!--Open Graph Related Stuff-->
  <meta property="og:title" content="2nd GenAI Media Generation Challenge Workshop"/>
  <meta property="og:url" content="https://sekunde.github.io/genai_eval"/>
  <meta property="og:description" content="2nd GenAI Media Generation Challenge, CVPR 2025 Workshop"/>
  <meta property="og:site_name" content="GenAI Media Generation Challenge Workshop"/>
  <meta property="og:image" content="https://sekunde.github.io/genai_eval/static/img/site/teaser.jpg"/>

  <!--Twitter Card Stuff-->
  <meta name="twitter:card" content="summary_large_image"/>
  <meta name="twitter:title" content="2nd GenAI Media Generation Challenge Workshop"/>
  <meta name="twitter:image" content="https://sekunde.github.io/genai_eval/static/img/site/teaser.jpg">
  <meta name="twitter:url" content="https://sekunde.github.io/genai_eval"/>
  <meta name="twitter:description" content="2nd GenAI Media Generation Challenge, CVPR 2025 Workshop"/>

  <!-- CSS  -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="static/css/main.css" media="screen,projection">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

  <style>

    .people-pic {
      max-width: 139px;
      max-height: 139px;
      /*width:300px;*/
      /*height:300px;*/
      object-fit: cover;
      border-radius: 50%;
  }

    .speaker-pic {
      max-width: 150px;
      max-height: 150px;
      /*width:300px;*/
      /*height:300px;*/
      object-fit: cover;
      border-radius: 50%;
  }
  </style>
</head>

  <body>

    <!-- <div class="top-strip"></div> -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="container">

    <div class="navbar-header">
      <a class="navbar-brand" href="/"></a>
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>

    <div class="navbar-collapse collapse" id="navbar-main">
      <ul class="nav navbar-nav">
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Past Workshops <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="cvpr2024/index.html" target="__blank">CVPR 2024</a></li>
          </ul>
        </li>
        <li><a href="#intro">Challenge Overview</a></li>
        <li><a href="#submission">Submission</a></li>
        <li><a href="#dates">Dates</a></li>
        <!-- <li><a href="#winners">Winners</a></li> -->
        <li><a href="#dates">Schedule</a></li>
        <li><a href="#speakers">Invited Speakers</a></li>
        <li><a href="#organizers">Organizers</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </div>

  </div>
</div>


    <div class="container">
      <div class="page-content">
          <p><br /></p>
<div class="row">
  <div class="col-xs-12">
    <center><h1>2nd GenAI Media Generation Challenge Workshop @ CVPR2025</h1></center>
    <center>TBA</center>
    <center>Workshop Meeting Location: TBA</center>
  </div>
</div>

<hr />


<div class="alert alert-info" role="alert">
  <center><b>Join Zoom Meeting  <a href="">TBA</a>.</b></center>
</div>


<div class="row" id="teaser">
    <div>
    <center>
      <video with="720" height="520" autoplay muted controls loop>
    <source src="static/img/site/teaser_video.mp4", type="video/mp4">
  </video>
  </center>
  </div>
</div>

<p><br /></p>
<div class="row" id="intro">
  <div class="col-xs-12">
    <h2>Workshop Overview</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">


    <p>
    This year, we are excited to host the 2nd GenAI Media Generation Challenge Workshop at CVPR 2025. Building on the success of last year's event, which focused on text-to-image and image editing tasks, we are expanding the challenge to include video generation.
    </p>
    <p>
    We are proud to announce the launch of the 2nd GenAI Media Generation Challenge (MAGIC), featuring a media generation track and auto-evaluation track:
      </p>
      <ul>
        <li>
          <b>Media Generation Festival:</b> For the first time, we are organizing a media generation festival with no restrictions on prompts. We would define a few different topics for which submitted media would compete in, and participants can submit their best videos for those specific topics. For each topic, we run a crowd sourced voting mechanism to determine the winners for each topic .
        </li>
        <li>
          <b>Auto Evaluation Challenge:</b> We are introducing an auto evaluation challenge for both text-to-image and text-to-video tasks. Participants can develop and submit their auto evaluation score for a preselect set of images and videos that we will provide and enter into the media generation festival track. Auto evaluation submissions would be to predict the outcomes from the crowd sourced voting mechanism in the media generation festival  The auto evaluation method that achieves the best correlation with the final results would be the winners for this challenge..
        </li>
      </ul>
    </p>

    <p><br /></p>
    <h2> Challenges Overview </h2>

    <H4>Challenge A -  Media Generation Festival</H4>
      <H5>Track A.1 - Video (Short)</H5>
      <p>
        For this task, there are no restrictions on prompts or models but limited to based on topics. Participants are free to use any models, including third-party video generation tools, and are encouraged to design their own creative prompts to produce engaging videos. Submissions can be single topic submissions or multiple topic submissions. However, the video length is limited to a maximum of 10 seconds.
      </p>
      <p>
        For this track, we will have the following set of of topics:
      </p>
      <ol>
        <li>
          People
        </li>
        <li>
          Animals
        </li>
        <li>
          Landscape
        </li>
      </ol>

      <H5>Track A.2 - Video (Long)</H5>
      <p>
        Similar to track A.1, there are no restrictions on prompts or models but limited to based on topics. For this track though, the video length is limited to a maximum of 5 minutes.
      </p>
      <p>
        For this track, we will have the following set of of topics:
      </p>
      <ol>
        <li>
          Action
        </li>
        <li>
          History
        </li>
        <li>
          Sci-Fi
        </li>
        <li>
          Fantasy
        </li>
        <li>
          Comedy
        </li>
      </ol>

      <H5>Track A.3 - Images</H5>
      <p>
        For this task, there are no restrictions on prompts or models but limited to based on topics. Participants are free to use any models, including third-party video generation tools, and are encouraged to design their own creative prompts to produce engaging videos.
      </p>
      <p>
        For this track, we will have the following set of of topics:
      </p>
      <ol>
        <li>
          People
        </li>
        <li>
          Animals
        </li>
        <li>
          Landscape
        </li>
      </ol>

      <H5>Evaluation Protocol</H5>


      <p>
        All submitted video/images will be uploaded to our crowdsourcing platform for public voting. The top three submissions with the highest votes for each topic will be declared winners. Beyond the winners per topic, we also have joint submission winners where we would have the best overall performing solution. We would use the Elo ranking system to compute the final ranking between different models.
      </p>

      <p>
        On automatic evaluation, we will leverage existing methods that have developed automatic
        metrics to help in assessing the outputs of the image based on the prompt.
      </p>

      <p>
        For the voting setup, we would use a pairwise comparison setup, showing two videos or images along with the topic, and ask the question "Which one would you prefer?". The selections would be 3-scale win/tie/lose rating.
      </p>

    <H4>Challenge B -  Results Prediction with Auto Evaluation</H4>

    In this challenge, we will use provided (text, image) pairs and (text, video) pairs for which participants would run their own auto evaluation metrics on. Participants will submit scores of these media which can be used to rank different media, or simply provide a ranking of all the videos in their submission.

      <H5>Track B.1 -  Video Generation Auto Eval </H5>
      <p>
        Please use videos from this <TBA>. Run your auto evaluation method on this set of videos and submit the auto evaluation results or ranking
      </p>

      <H5>Track B.2 -  Image Generation Auto Eval </H5>

      <p>
        Please use images from this <TBA>. Run your auto evaluation method on this set of videos and submit the auto evaluation results or ranking
      </p>


      <H5>Evaluation Protocol</H5>


      <p>
        All submitted video/images will be uploaded to our crowdsourcing platform for public voting. The top three submissions with the highest votes for each topic will be declared winners. Beyond the winners per topic, we also have joint submission winners where we would have the best overall performing solution. We would use the Elo ranking system to compute the final ranking between different models.
      </p>

      <p>
        On automatic evaluation, we will leverage existing methods that have developed automatic
        metrics to help in assessing the outputs of the image based on the prompt.
      </p>

      <p>
        For the voting setup, we would use a pairwise comparison setup, showing two videos or images along with the topic, and ask the question "Which one would you prefer?". The selections would be 3-scale win/tie/lose rating.
      </p>


    <p><br /></p>

<div class="row" id="submission">
  <div class="col-xs-12">
    <h2>Challenge Registration / Submission </h2>

    <h3> Mailing List Registration</h3>
    <p> For all parties interested in participating, we ask you to sign up to our mailing list throught the google form here: TBD.</p>

      <h3>Submission Instructions</h3>
      Submission instructions have been sent out to participants via email. Please register above to receive instructions on the mailing list above.


  </div>
</div>


<p><br /></p>
<div class="row" id="leaderboard">
  <div class="col-xs-12">
    <h2>Leaderboard</h2>
  </div>
</div>
<div class="row">
  <div class="col-md-12">
    TBA
   <!-- <table>
      <tbody>
      <tr><td><a href="https://arxiv.org/abs/2212.01558">#1. Emu</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Zuck, Boz</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2112.08359">#2. EmuV2</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Zuck, Ahmad</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2211.11682">#3. EmuV3</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Boz, Xiaoliang</font></td> </tr>
      <tr><td><a href="https://arxiv.org/abs/2211.11682">#3. EmuV4</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Kunkun</font></td> </tr>

    </tbody></table>
    -->
  </div>

</div>

<!--
<p><br /></p>
<div class="row" id="winners">
  <div class="col-xs-12">
    <h2>Winners</h2>
  </div>
</div>
TBD -->

<p><br /></p>

<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
   <table class="table table-striped">
      <tbody>
        <tr>
          <td>Description</td>
          <td>Date</td>
        </tr>
        <tr>
          <td>Submission opens for all Challenges.</td>
          <td>3/3/2025</td>
        </tr>
        <tr>
          <td>Submission closes for Challenge A.</td>
          <td>4/14/2025</td>
        </tr>
        <tr>
          <td>Crowd-sourced polling opens</td>
          <td>4/21/2025</td>
        </tr>
        <tr>
          <td>Submission closes for Challenge B.</td>
          <td>6/2/2025</td>
        </tr>
        <tr>
          <td>Crowd-sourced poll ends.</td>
          <td>6/2/2025</td>
        </tr>
        <tr>
          <td>Workshop Date</td>
          <td>TBD </td>
        </tr>

      </tbody>
    </table>

  </div>
</div>

<p><br /></p>
<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Workshop Schedule</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    TBA
<!--
  <table class="table table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Time</th>
      <th>Agenda</th>
      <th>Speech Title</th>
      <th>Speaker(s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>

      <td>Opening Session</td>
      <td>13:15 - 13:30</td>
      <td>Opening Remarks</td>
      <td></td>
      <td>Workshop Organizers</td>
    </tr>
    <tr>
      <td rowspan="3">Session I</td>
      <td>13:30 - 14:00</td>
      <td>Keynote Speech</td>
      <td>Known Issues with FID and FVD</td>
      <td>Jun-Yan Zhu</td>
    </tr>
    <tr>
      <td>14:00 - 14:30</td>
      <td>Keynote Speech</td>
      <td>Video Generation: Past, Present, and a New Hope</td>
      <td>Sergey Tulyakov</td>
    </tr>
    <tr>
      <td>14:30 - 15:00</td>
      <td>Keynote Speech</td>
      <td>Incentivizing Opt-in & Enabling Opt-out for Text-to-Image Models</td>
      <td>Richard Zhang</td>
    </tr>
    <tr>
      <td>Break</td>
      <td>15:00 - 15:20</td>
      <td colspan="3">Coffee Break</td>
    </tr>
    <tr>
      <td rowspan="4">Session II</td>
        <td>15:20 - 15:50</td>
      <td>Keynote Speech</td>
      <td>Controllable Media Generation</td>
      <td>Yuanzhen Li</td>
    </tr>
    <tr>
      <td>15:50 - 16:20</td>
      <td>Keynote Speech</td>
      <td>Multistep Distillation of Diffusion Models via Moment Matching</td>
      <td>Tim Salimans</td>
    </tr>
    <tr>
      <td>16:20 - 17:00</td>
      <td colspan="2">Competition Evaluation, Goals, Awards and Participant Presentations</td>
      <td>Workshop Organizers, Ju Xuan, Manuel Brack, Lumina, Akio</td>
    </tr>
    <tr>
      <td>17:00 - 17:30</td>
      <td>Panel Discussion</td>
    <td>Evaluation and tracking progress for Generative AI</td>
      <td>Jun-Yan Zhu, Richard Zhang, Ishan Misra</td>
    </tr>
    <tr>
      <td>Closing Session</td>
      <td>17:30 - 17:40</td>
      <td colspan="2">Closing Remarks</td>
      <td>Workshop Organizers</td>
    </tr>
  </tbody>
</table>
-->
  </div>
</div>

<p><br /></p>

<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Invited Speakers</h2>
  </div>
</div>

<div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/bjoern_ommer.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://ommer-lab.com/people/ommer/">Björn Ommer</a></b> Dr. Björn Ommer is a full professor at LMU where he heads the Computer Vision & Learning Group (previously Computer Vision Group Heidelberg). Before he was a full professor at the Department of Mathematics and Computer Science of Heidelberg University and also served as a one of the directors of the Interdisciplinary Center for Scientific Computing (IWR) and of the Heidelberg Collaboratory for Image Processing (HCI). He has served as program chair for GCPR, as Senior Area Chair and Area Chair for multiple CVPR, ICCV, ECCV, and NeurIPS conferences, and as workshop and tutorial organizer at these venues.   </p>
  </div>
</div>

<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/junyan_zhu.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a></b> Dr. Jun-Yan Zhu is an Assistant Professor with The Robotics Institute in the School of
      Computer Science of Carnegie Mellon University. He also holds affiliated faculty
      appointments in the Computer Science Department and Machine Learning Department.
      He studies computer graphics, computer vision, and computational photography. Prior to
      joining CMU, he was a Research Scientist at Adobe Research. He did a postdoc at MIT
      CSAIL, working with William T. Freeman, Josh Tenenbaum, and Antonio Torralba. He
      obtained my Ph.D. from UC Berkeley, under the supervision of Alexei A. Efros. He
      received his B.E. from Tsinghua University, working with Zhuowen Tu, Shi-Min Hu, and
      Eric Chang.
    </p>
  </div>
</div>

<p><br /></p>
    <div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/sergey_tulyakov.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="http://www.stulyakov.com/">Sergey Tulyakov</a></b> Dr. Sergey Tulyakov is a Principal Research Scientist heading the Creative Vision team at
      Snap Research. His work focuses on creating methods for manipulating the world via
      computer vision and machine learning. This includes 2D and 3D methods for
      photorealistic object manipulation and animation, video synthesis, prediction and
      retargeting. His work has been published as 30+ top conference papers, journals and
      patents resulting in multiple tech transfers, including Snapchat Pet Tracking and
      Real-time Neural Lenses (gender swap, baby face, real-time try-on and many others).
  </div>

</div>

<p><br /></p>

  <div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/saining_xie.png" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://www.sainingxie.com/">Saining Xie</a></b> Dr. Saining Xie is an Assistant Professor of Computer Science at NYU Courant and part of the CILVR group. He is also affiliated with NYU Center for Data Science. Before that I was a research scientist at Facebook AI Research (FAIR), Menlo Park. He received my Ph.D. and M.S. degrees from CSE Department at UC San Diego, advised by Zhuowen Tu. During his PhD study, he also interned at NEC Labs, Adobe, Facebook, Google, DeepMind. Prior to that, he obtained his bachelor degree from Shanghai Jiao Tong University. His primary areas of interest in research are computer vision and machine learning.
</div>


</div>
<!---

<div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px" src="static/img/people/yuanzhen_li.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://people.csail.mit.edu/yzli/">Yuanzhen Li</a></b> At Google Research, Yuanzhen supports a talented team and a few cross-team Computer Vision and Generative AI efforts. Recent work includes: Generative Product Imagery, "Imagen" in Google Cloud Vertex AI, Muse, DreamBooth, DreamBooth3D, Generative Uncrop, etc. Prior to Google, she spent 10 years in the startup world. She made iPhone computational-photography apps, and one of them (TrueHDR) was quite popular in the 2009-2012 era. She also founded a startup leveraging deep learning for image search; it was acquired by VSCO in 2015 and I then worked at VSCO as a Director of Engineering. Prior to that, she completed my PhD in 2009 at MIT with Prof. Edward H. Adelson. At MIT, she was a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and the Perceptual Science Laboratory.
    </p>
  </div>
</div>

<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/richard_zhang.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://richzhang.github.io/">Richard Zhang</a></b> Dr. Richard Zhang’s research interests are in computer vision, machine learning, deep
      learning, graphics, and image processing. He obtained a PhD at UC Berkeley, advised by
      Prof. Alexei (Alyosha) Efros. He obtained BS and MEng degrees from Cornell University
      in ECE. He often collaborates with academic researchers, either through internships or
      university collaboration. Recently, he was included on MIT Technology Review's list of 35
      Innovators Under 35.
  </div>
</div>


<p><br /></p>

    <div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/tim_salimans.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://research.google/people/tim-salimans/">Tim Salimans</a></b> Tim is a Machine Learning research scientist working on generative modeling. He is well known for his work on GANs and VAEs, and their evaluation using the Inception score, as well as his work on autoregressive generative models like GPT-1 and PixelCNN++. More recently, he has been focusing on diffusion models for generating images (Imagen) and video (Imagen Video), and on making these models fast to sample using distillation.
  </div>

</div>

-->


<p><br /></p>
<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>

<div class="row">

 <div class="col-xs-2">
    <a href="https://scholar.google.com/citations?user=JdE_LFYAAAAJ&hl=en">
      <img class="people-pic" src="static/img/people/sam_tsai.jpg" />
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=JdE_LFYAAAAJ&hl=en">Sam Tsai</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://sekunde.github.io">
      <img class="people-pic" src="static/img/people/ji_hou.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sekunde.github.io/">Ji Hou</a>
      <h6>Meta AI</h6>
    </div>
  </div>


  <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/ajay-menon-022650267">
      <img class="people-pic" src="static/img/people/luxin_zhang.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/ajay-menon-022650267">Luxin Zhang</a>
      <h6>Meta AI</h6>
    </div>
  </div>


  <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/ajay-menon-022650267">
      <img class="people-pic" src="static/img/people/yaqiao_luo.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/ajay-menon-022650267">Yaqiao Luo</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://kunpengli1994.github.io/">
      <img class="people-pic" src="static/img/people/kunpeng_li.jpg" />
    </a>
    <div class="people-name">
      <a href="https://kunpengli1994.github.io/">Kunpeng Li</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://sites.google.com/view/xiaoliangdai/">
      <img class="people-pic" src="static/img/people/xiaoliang_dai.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/view/xiaoliangdai/">Xiaoliang Dai</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://chihyaoma.github.io">
      <img class="people-pic" src="static/img/people/kevin_ma.jpg" />
    </a>
    <div class="people-name">
      <a href="https://chihyaoma.github.io/">Kevin Chih-Yao Ma</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://openreview.net/profile?id=~Matthew_Yu2">
      <img class="people-pic" src="static/img/people/matthew_yu.jpg" />
    </a>
    <div class="people-name">
      <a href="https://openreview.net/profile?id=~Matthew_Yu2">Matthew Yu</a>
      <h6>Meta AI</h6>
    </div>
  </div>


  <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/tianhe-li/">
      <img class="people-pic" src="static/img/people/tianhe_li.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/tianhe-li/">Tianhe Li</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/simran-motwani">
      <img class="people-pic" src="static/img/people/simran_motwani.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/simran-motwani">Simran Motwani</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/ajay-menon-022650267">
      <img class="people-pic" src="static/img/people/maxime.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/ajay-menon-022650267">Maxime Seknadje</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://sites.google.com/view/taoxu">
      <img class="people-pic" src="static/img/people/tao_xu.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/view/taoxu">Tao Xu</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://sites.google.com/view/jialiangwang/home">
      <img class="people-pic" src="static/img/people/jialiang_wang.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/view/jialiangwang/home">Jialiang Wang</a>
      <h6>Meta AI</h6>
    </div>
  </div>

    <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/karthiksivakumar/">
      <img class="people-pic" src="static/img/people/karthik_sivakumar.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/karthiksivakumar/">Karthik Sivakumar</a>
      <h6>Meta AI</h6>
    </div>
  </div>


</div>
<p><br /></p>
<p><br /></p>

<div class="row" id="advisors">
  <div class="col-xs-12">
    <h2>Senior Advisors</h2>
  </div>
</div>

<div class="row">

  <div class="col-xs-2">
    <a href="https://sites.google.com/site/vajdap">
      <img class="people-pic" src="static/img/people/peter_vajda.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/site/vajdap">Peter Vajda</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://scholar.google.com/citations?user=eqQQkM4AAAAJ&hl=en">
      <img class="people-pic" src="static/img/people/peizhao_zhang.jpg" />
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=eqQQkM4AAAAJ&hl=en">Peizhao Zhang</a>
      <h6>Meta AI</h6>
    </div>
  </div>

    <div class="col-xs-2">
    <a href="http://www.stulyakov.com/">
      <img class="people-pic" src="static/img/people/sergey_tulyakov.jpg" />
    </a>
    <div class="people-name">
      <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>
      <h6>Snap</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://scholar.google.com/citations?user=G03EzSMAAAAJ&hl=en">
      <img class="people-pic" src="static/img/people/zijian_he.jpg" />
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=G03EzSMAAAAJ&hl=en">Zijian He</a>
      <h6>Meta AI</h6>
    </div>
  </div>


  <div class="col-xs-2">
    <a href="https://www.alithabet.com/">
      <img class="people-pic" src="static/img/people/ali_thabet.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.alithabet.com/">Ali Thabet</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://ai.meta.com/people/roshan-sumbaly/">
      <img class="people-pic" src="static/img/people/roshan_sumbaly.jpg" />
    </a>
    <div class="people-name">
      <a href="https://ai.meta.com/people/roshan-sumbaly/">Roshan Sumbaly</a>
      <h6>Meta AI</h6>
    </div>
  </div>


</div>

<p><br /></p>

<div class="row" id="contact">
  <div class="col-xs-12">
    <h2>Contact</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      To contact the organizers please use <b>gen_ai_media_generation_challenge_cvpr_workshop@meta.com</b>
    </p>
  </div>
</div>
<p><br /></p>

<hr />

<div class="row">
  <div class="col-xs-12">
    <h2>Acknowledgments</h2>
  </div>
</div>
<p><a name="/acknowledgements"></a></p>
<div class="row">
  <div class="col-xs-12">
    <p>
      Thanks to <span style="color:#1a1aff;font-weight:400;"> <a href="https://languagefor3dscenes.github.io/">languagefor3dscenes</a></span> for the webpage format.
    </p>
  </div>
</div>

      </div>
    </div>

  </body>
</html>
