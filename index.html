
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="keywords" content="eccv, workshop, computer vision, natural language processing, computer graphics, visual learning, machine learning">

  <link rel="shortcut icon" href="static/img/site/favicon.png">

  <title>GenAIMAGIC@CVPR24</title>
  <meta name="description" content="GenAI Media Generation Challenge, CVPR 2024 Workshop">

  <!--Open Graph Related Stuff-->
  <meta property="og:title" content="GenAI Media Generation Challenge Workshop"/>
  <meta property="og:url" content="https://sekunde.github.io/genai_eval"/>
  <meta property="og:description" content="GenAI Media Generation Challenge, CVPR 2024 Workshop"/>
  <meta property="og:site_name" content="GenAI Media Generation Challenge Workshop"/>
  <meta property="og:image" content="https://sekunde.github.io/genai_eval/static/img/site/teaser.jpg"/>

  <!--Twitter Card Stuff-->
  <meta name="twitter:card" content="summary_large_image"/>
  <meta name="twitter:title" content="GenAI Media Generation Challenge Workshop"/>
  <meta name="twitter:image" content="https://sekunde.github.io/genai_eval/static/img/site/teaser.jpg">
  <meta name="twitter:url" content="https://sekunde.github.io/genai_eval"/>
  <meta name="twitter:description" content="GenAI Media Generation Challenge, CVPR 2024 Workshop"/>

  <!-- CSS  -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="static/css/main.css" media="screen,projection">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

  <style>

    .people-pic {
      max-width: 139px;
      max-height: 139px;
      /*width:300px;*/
      /*height:300px;*/
      object-fit: cover;
      border-radius: 50%;
  }

    .speaker-pic {
      max-width: 150px;
      max-height: 150px;
      /*width:300px;*/
      /*height:300px;*/
      object-fit: cover;
      border-radius: 50%;
  }
  </style>
</head>

  <body>

    <!-- <div class="top-strip"></div> -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="container">

    <div class="navbar-header">
      <a class="navbar-brand" href="/"></a>
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>

    <div class="navbar-collapse collapse" id="navbar-main">
      <ul class="nav navbar-nav">
        <li><a href="#intro">Challenge Overview</a></li>
        <li><a href="#submission">Submission</a></li>
        <li><a href="#dates">Dates</a></li>
        <!-- <li><a href="#winners">Winners</a></li> -->
        <li><a href="#dates">Schedule</a></li>
        <li><a href="#speakers">Invited Speakers</a></li>
        <li><a href="#organizers">Organizers</a></li>
        <li><a href="#contact">Contact</a></li>
        <!-- <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Past Workshops <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="../CVPR2021/index.html" target="__blank">CVPR 2021</a></li>
            <li><a href="../ECCV2022/" target="__blank">ECCV 2022</a></li>
          </ul>
        </li>
      -->
      </ul>
    </div>

  </div>
</div>


    <div class="container">
      <div class="page-content">
          <p><br /></p>
<div class="row">
  <div class="col-xs-12">
    <center><h1>GenAI Media Generation Challenge Workshop @ CVPR</h1></center>
    <center>Jun 17 (afternoon), 2024</center>
  </div>
</div>

<hr />


<!--
<div class="alert alert-info" role="alert">
  <center><b>Join Zoom Meeting  <a href="">here</a>.</b></center>
</div> -->



<div class="row" id="teaser">
    <div>
    <center><img src="static/img/site/teaser.png" style="width: 90%; height: auto;"/></center>
  </div>
</div>

<p><br /></p>
<div class="row" id="intro">
  <div class="col-xs-12">
    <h2>Challenge Overview</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">

    <p>
      In the wake of the rapid advancements in generative model capabilities, the field of text-guided image generation and editing has seen unprecedented progress. This has resulted in the creation of images with unparalleled quality, aesthetics, and adherence to text guidance. Yet, a significant challenge remains: the absence of a universally-accepted, easily accessible benchmark for evaluating in-depth capabilities of the generated models. This issue stems from the lack of a comprehensive, large-scale evaluation dataset, standardized evaluation protocols, and the insufficiency of current automatic metrics.
    </p>
    <p>
      We are proud to announce the launch of the GenAI Media Generation Challenge (MAGIC) that moves us towards addressing these issues. We host two challenge tracks: (1) text to image generation, and (2) text guided image editing, and will be providing the following set of data and resources:
      <ul>
        <li>
          Benchmark Datasets: diverse and comprehensive datasets will be released publicly for both tracks, ensuring that all participants have access to the same information and resources.
        </li>
        <li>
          Evaluation Protocol: A standardized evaluation protocol and metrics will be established and shared with all participants. This metric will be designed keeping in mind the nuances and specifics of the tasks, ensuring fair and objective evaluation.
        </li>
        <li>
          Human Annotations for all Submissions: Recognizing the importance of meticulous human oversight, we commit to offering the requisite human annotation resources as stipulated by the evaluation protocol for the duration of the competition.
        </li>
        <li>
          Baselines: For aiding participants and setting a preliminary standard, baseline results will be shared.
        </li>
        <li>
          Awards for top performing participants for different tracks and challenges.
        </li>
      </ul>
    </p>
    <p>
      In addition to the benchmark dataset, after the challenge, we will be releasing all human annotations for all submissions for the participants. This hopefully would be a contribution to the community for future evaluation tooling development.
    </p>

<!-- <div class="row" id="challenges">
  <div class="col-xs-12"> -->
    <p><br /></p>
    <h3>Tracks Overview</h3>
  <!-- </div>
</div> -->
    <H4>Track A - Text-to-image Generation</H4>
      <H5>Benchmarking Datasets </H5>
      <p>
        For this track, we test the model's text to image generation capabilities using benchmark prompts with different scenarios and complexity.
        Benchmark prompts will be leveraging existing academic benchmarks and newly constructed prompts which expands to different levels of complexity. We aim to test different scenarios as below with different benchmark prompts:
      <ol>
        <li>
          Single object generation, focusing on generation accuracy and correctness of the object
        </li>
        <li>
          Object composition, focusing on generation along with relationship and activity
        </li>
        <li>
          Reasoning, focusing on concepts such as counting or logic
        </li>
        <li>
          Stylization, focusing on correctness of global style
        </li>
        <li>
          Rendered text, focusing on quality and correctness of the generated text in image.
        </li>
        </li>
      </ol>
      </p>
      <p>
      Within these scenarios, the benchmark prompts would contain topics from various domains.
      For example, for single object generation, there prompts looking at generation of people, animals, food, and locations.
      </p>

      <H5>Evaluation Protocol</H5>


      <p>
        We leverage both human and automated evaluations.
        On human-based evaluations, we use human annotators to annotate the of the text2Image model performance on the following aspects:
        <ol>
          <li>Text Faithfulness - whether the visual elements in prompts such as objects, attributes,
            interactions are accurately generated in the image. </li>
          <li>Visual quality - whether there are visual errors/defects in the generated image. Examples of errors/defects
            include misplaced body parts for people, unrealistic scale, bad arrangement, or blurry.</li>
          <li>Visual appeal - whether the generated images are aesthetically pleasing to view. We judge whether models are either
            on-par or surpass professionally made ones in terms of abundant visual details, color harmony, and composition.</li>
        </ol>
      </p>

      <p>
        On automatic evaluation, we will leverage existing methods that have developed automatic
        metrics to help in assessing the outputs of the image based on the prompt.
      </p>

      <p>
        To determine winners, we use automatic evaluation to help prune the total number entries to 10 finalists. Within the final 10 participants, we would use human evaluation results to determine the final winners.
      </p>

    <H4>Track B - Text-guided Image Editing</H4>

      <H5>Benchmarking Dataset</H5>
      <p>
        For text guided image editing, we test the capacity of the model to change a given
        image's contents based on some text instructions. The specific type of instructions   that we test for are the following:
        <ol>
          <li>
            Addition: Adding new objects within the images.
          </li>
          <li>
          Remove: Removing objects
          </li>
          <li>
            Local: Replace local parts of an object and later the object's attributes, i.e., make it smile
          </li>
          <li>
          Global: Edit the entire image, i.e., let's see it in winter
          </li>
          <li>
            Inpaint: Alter an object's visual appearance without affecting its structure
          </li>
            <li>
          Background: Change the scene's background
          </li>
        </ol>
      </p>

      <H5>Evaluation Protocol</H5>

      <p>
        We leverage both human and automated evaluations. On human-based evaluations, we use human annotators to annotate the we mainly evaluate the following aspects:
      <ol>
      <li>Edit faithfulness - whether the edited image follows the editing instruction</li>
      <li>Content preservation - whether the edited image preserves the regions of the original image which should not be changed</li>
      <li>Visual quality - whether the edited image is artifact-free, keeping the core visual features of the original image, etc</li>
      </ol>
      </p>

      <p>
      On automatic evaluation, similar to the text to image track, we will leverage existing methods that have developed automatic metrics to help in assessing the outputs of the image based on the prompt and instruction.
      </p>


      <p>
      To determine winners, we use automatic evaluation to help prune the total number entries to 10 finalists. At 10, we would use human annotation and evaluation to determine the final winners.
      </p>

      <p><br /></p>
      <H3>Winner Prize</H3>
    <p>
      Top three contestants of each track will be awarded with the latest generation of AR/VR headsets from Meta.
    </p>

    <p><br /></p>

<div class="row" id="submission">
  <div class="col-xs-12">
    <h2>Challenge Registration / Submission </h2>

    <h3> Mailing List Registration</h3>
    <p> For all parties interested in participating, we ask you to sign up to our mailing list throught the google form here: [<a href="https://docs.google.com/forms/d/e/1FAIpQLSeA4MOy5QdQiPqGrWMiJg0NNZRSwG8FSs1emCvYPFCBFHq2gg/viewform?usp=sf_link">Register Mailing List</a>].

      </p>

      <p><br /></p>
      <h3>Submission Instructions</h3>
      Submission instructions have been sent out to participants via email. Please register above to receive instructions on the mailing list above.


  </div>
</div>


<p><br /></p>
<div class="row" id="leaderboard">
  <div class="col-xs-12">
    <h2>Leaderboard</h2>
  </div>
</div>
<div class="row">
  <div class="col-md-12">
    To be updated on May 18.
   <!-- <table>
      <tbody>
      <tr><td><a href="https://arxiv.org/abs/2212.01558">#1. Emu</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Zuck, Boz</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2112.08359">#2. EmuV2</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Zuck, Ahmad</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2211.11682">#3. EmuV3</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Boz, Xiaoliang</font></td> </tr>
      <tr><td><a href="https://arxiv.org/abs/2211.11682">#3. EmuV4</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Kunkun</font></td> </tr>

    </tbody></table>
    -->
  </div>

</div>

<!--
<p><br /></p>
<div class="row" id="winners">
  <div class="col-xs-12">
    <h2>Winners</h2>
  </div>
</div>
TBD -->

<p><br /></p>

<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates (Seattle / Pacific Time Zone)</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
   <table class="table table-striped">
      <tbody>
        <tr>
          <td>Registration Open</td>
          <td>March 4</td>
        </tr>
        <tr>
          <td>Release of Benchmarking Datasets</td>
          <td><s>March 22</s> April 5</td>
        </tr>
        <tr>
          <td>Challenge Submission Deadline</td>
          <td><s> April 26, 5pm PST</s> May 1st, 11:59pm PST</td>
        </tr>
        <tr>
          <td>Announcement of Challenge Winners</td>
          <td>May 18 </td>
        </tr>
        <tr>
          <td>Workshop Date</td>
          <td>June 17 </td>
        </tr>

      </tbody>
    </table>

  </div>
</div>

<p><br /></p>
<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Workshop Schedule (Pacific Time Zone)</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    TBD
    <!--
     <table class="table table-striped">
      <tbody>
        <tr>
          <td>Welcome</td>
          <td>2:00pm - 2:05pm / 5:00am - 4:05am</td>
        </tr>
        <tr>
          <td>Invited Talk </td>
          <td>2:05pm - 2:30pm / 5:05am - 5:30am</td>
        </tr>
        <tr>
          <td>Presentation of challenge winners</td>
          <td>2:30pm - 2:55pm / 5:30am - 5:55am</td>
        </tr>
        <tr>
          <td>Invited Talk</td>
          <td>3:30pm - 4:00pm / 6:30am - 7:00am</td>
        </tr>
          <td>Panel discussion</td>
          <td>5:00pm - 5:40pm / 8:00am - 8:40am</td>
        </tr>
        <tr>
          <td>Concluding Remarks</td>
          <td>5:40pm - 5:50pm / 8:40am - 8:50am</td>
        </tr>
      </tbody>
    </table>
    -->

  </div>
</div>

<p><br /></p>



<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Invited Speakers</h2>
  </div>
</div>

<div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px" src="static/img/people/yuanzhen_li.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://people.csail.mit.edu/yzli/">Yuanzhen Li</a></b> At Google Research, Yuanzhen supports a talented team and a few cross-team Computer Vision and Generative AI efforts. Recent work includes: Generative Product Imagery, "Imagen" in Google Cloud Vertex AI, Muse, DreamBooth, DreamBooth3D, Generative Uncrop, etc. Prior to Google, she spent 10 years in the startup world. She made iPhone computational-photography apps, and one of them (TrueHDR) was quite popular in the 2009-2012 era. She also founded a startup leveraging deep learning for image search; it was acquired by VSCO in 2015 and I then worked at VSCO as a Director of Engineering. Prior to that, she completed my PhD in 2009 at MIT with Prof. Edward H. Adelson. At MIT, she was a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and the Perceptual Science Laboratory.
    </p>
  </div>
</div>

<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/junyan_zhu.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a></b> Dr. Jun-Yan Zhu is an Assistant Professor with The Robotics Institute in the School of
      Computer Science of Carnegie Mellon University. He also holds affiliated faculty
      appointments in the Computer Science Department and Machine Learning Department.
      He studies computer graphics, computer vision, and computational photography. Prior to
      joining CMU, he was a Research Scientist at Adobe Research. He did a postdoc at MIT
      CSAIL, working with William T. Freeman, Josh Tenenbaum, and Antonio Torralba. He
      obtained my Ph.D. from UC Berkeley, under the supervision of Alexei A. Efros. He
      received his B.E. from Tsinghua University, working with Zhuowen Tu, Shi-Min Hu, and
      Eric Chang.
    </p>
  </div>
</div>

<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/richard_zhang.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://richzhang.github.io/">Richard Zhang</a></b> Dr. Richard Zhang’s research interests are in computer vision, machine learning, deep
      learning, graphics, and image processing. He obtained a PhD at UC Berkeley, advised by
      Prof. Alexei (Alyosha) Efros. He obtained BS and MEng degrees from Cornell University
      in ECE. He often collaborates with academic researchers, either through internships or
      university collaboration. Recently, he was included on MIT Technology Review's list of 35
      Innovators Under 35.
  </div>
</div>

<p><br /></p>

    <div class="row">
  <div class="col-md-2">
    <a href=""><img class="speaker-pic" style="float:left;margin-right:50px;" src="static/img/people/sergey_tulyakov.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="http://www.stulyakov.com/">Sergey Tulyakov</a></b> Dr. Sergey Tulyakov is a Principal Research Scientist heading the Creative Vision team at
      Snap Research. His work focuses on creating methods for manipulating the world via
      computer vision and machine learning. This includes 2D and 3D methods for
      photorealistic object manipulation and animation, video synthesis, prediction and
      retargeting. His work has been published as 30+ top conference papers, journals and
      patents resulting in multiple tech transfers, including Snapchat Pet Tracking and
      Real-time Neural Lenses (gender swap, baby face, real-time try-on and many others).
  </div>
</div>

<p><br /></p>


<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>

<div class="row">

 <div class="col-xs-2">
    <a href="https://scholar.google.com/citations?user=JdE_LFYAAAAJ&hl=en">
      <img class="people-pic" src="static/img/people/sam_tsai.jpg" />
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=JdE_LFYAAAAJ&hl=en">Sam Tsai</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://sekunde.github.io">
      <img class="people-pic" src="static/img/people/ji_hou.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sekunde.github.io/">Ji Hou</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://scholar.google.com/citations?user=K3QJPdMAAAAJ&hl=en">
      <img class="people-pic" src="static/img/people/bichen_wu.jpg" />
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=K3QJPdMAAAAJ&hl=en">Bichen Wu</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://sites.google.com/view/xiaoliangdai/">
      <img class="people-pic" src="static/img/people/xiaoliang_dai.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/view/xiaoliangdai/">Xiaoliang Dai</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://chihyaoma.github.io">
      <img class="people-pic" src="static/img/people/kevin_ma.jpg" />
    </a>
    <div class="people-name">
      <a href="https://chihyaoma.github.io/">Kevin Chih-Yao Ma</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://openreview.net/profile?id=~Matthew_Yu2">
      <img class="people-pic" src="static/img/people/matthew_yu.jpg" />
    </a>
    <div class="people-name">
      <a href="https://openreview.net/profile?id=~Matthew_Yu2">Matthew Yu</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://ai.meta.com/people/rui-wang/">
      <img class="people-pic" src="static/img/people/rui_wang.jpg" />
    </a>
    <div class="people-name">
      <a href="https://ai.meta.com/people/rui-wang/">Wang Rui</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/tianhe-li/">
      <img class="people-pic" src="static/img/people/tianhe_li.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/tianhe-li/">Tianhe Li</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/simran-motwani">
      <img class="people-pic" src="static/img/people/simran_motwani.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/simran-motwani">Simran Motwani</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/ajay-menon-022650267">
      <img class="people-pic" src="static/img/people/ajay_menon.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/ajay-menon-022650267">Ajay Menon</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://kunpengli1994.github.io/">
      <img class="people-pic" src="static/img/people/kunpeng_li.jpg" />
    </a>
    <div class="people-name">
      <a href="https://kunpengli1994.github.io/">Kunpeng Li</a>
      <h6>Meta AI</h6>
    </div>
  </div>


  <div class="col-xs-2">
    <a href="https://sites.google.com/view/taoxu">
      <img class="people-pic" src="static/img/people/tao_xu.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/view/taoxu">Tao Xu</a>
      <h6>Meta AI</h6>
    </div>
  </div>


    <div class="col-xs-2">
    <a href="https://sites.google.com/view/jialiangwang/home">
      <img class="people-pic" src="static/img/people/jialiang_wang.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/view/jialiangwang/home">Jialiang Wang</a>
      <h6>Meta AI</h6>
    </div>
  </div>

      <div class="col-xs-2">
    <a href="https://www.linkedin.com/in/karthiksivakumar/">
      <img class="people-pic" src="static/img/people/karthik_sivakumar.jpg" />
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/karthiksivakumar/">Karthik Sivakumar</a>
      <h6>Meta AI</h6>
    </div>
  </div>



</div>
<p><br /></p>
<p><br /></p>

<div class="row" id="advisors">
  <div class="col-xs-12">
    <h2>Senior Advisors</h2>
  </div>
</div>

<div class="row">

  <div class="col-xs-2">
    <a href="https://sites.google.com/site/vajdap">
      <img class="people-pic" src="static/img/people/peter_vajda.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/site/vajdap">Peter Vajda</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://scholar.google.com/citations?user=eqQQkM4AAAAJ&hl=en">
      <img class="people-pic" src="static/img/people/peizhao_zhang.jpg" />
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=eqQQkM4AAAAJ&hl=en">Peizhao Zhang</a>
      <h6>Meta AI</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://n-zhang.github.io/">
      <img class="people-pic" src="static/img/people/ning_zhang.jpg" />
    </a>
    <div class="people-name">
      <a href="https://n-zhang.github.io/">Ning Zhang</a>
      <h6>Meta AI</h6>
    </div>
  </div>

    <div class="col-xs-2">
    <a href="http://www.stulyakov.com/">
      <img class="people-pic" src="static/img/people/sergey_tulyakov.jpg" />
    </a>
    <div class="people-name">
      <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>
      <h6>Snap</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://scholar.google.com/citations?user=G03EzSMAAAAJ&hl=en">
      <img class="people-pic" src="static/img/people/zijian_he.jpg" />
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=G03EzSMAAAAJ&hl=en">Zijian He</a>
      <h6>Meta AI</h6>
    </div>
  </div>


  <div class="col-xs-2">
    <a href="https://ai.meta.com/people/roshan-sumbaly/">
      <img class="people-pic" src="static/img/people/roshan_sumbaly.jpg" />
    </a>
    <div class="people-name">
      <a href="https://ai.meta.com/people/roshan-sumbaly/">Roshan Sumbaly</a>
      <h6>Meta AI</h6>
    </div>
  </div>


</div>

<p><br /></p>

<div class="row" id="contact">
  <div class="col-xs-12">
    <h2>Contact</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      To contact the organizers please use <b>gen_ai_media_generation_challenge_cvpr_workshop@meta.com</b>
    </p>
  </div>
</div>
<p><br /></p>

<hr />

<div class="row">
  <div class="col-xs-12">
    <h2>Acknowledgments</h2>
  </div>
</div>
<p><a name="/acknowledgements"></a></p>
<div class="row">
  <div class="col-xs-12">
    <p>
      Thanks to <span style="color:#1a1aff;font-weight:400;"> <a href="https://languagefor3dscenes.github.io/">languagefor3dscenes</a></span> for the webpage format.
    </p>
  </div>
</div>

      </div>
    </div>

  </body>
</html>
